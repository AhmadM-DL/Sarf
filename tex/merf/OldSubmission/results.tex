In this section we compare \framework implementations of 
the narrator chain, temporal entity, and genealogy entity extration 
tasks to the task specific techniques proposed to solve them
in ANGE~\cite{ZaMaFlairs2012HadithBio}, 
ATEEMA~\cite{ZaMa2012IJCLATime},  and
GENTREE~\cite{ZaMaHaCicling2012Entity}, respectively. 
We also compare a \framework number normalization task to 
a task specific implementation. 
In the online appendix%
~\footnote{Appendix available at ~\url{http://webfea.fea.aub.edu.lb/fadi/pdfs/merfappendix.pdf}}%
, we report on eight additional \framework case studies.

Table~\ref{tab:results} reports the development time,
entity extraction runtime, recall and precision accuracy metrics
of the output MRE tags, 
the size of the task in lines of code or in number of \framework rules, 
for both the standalone task specific and the \framework implementations. 
%Table~\ref{tab:mbfer} reports the accuracy of the output MBF tags and the user-defined relation 
%construction in \framework for each task.

% Table generated by Excel2LaTeX from sheet 'Sheet1'
\begin{table}[tb!]
  \centering
\caption{\framework compared to task specific applications.}
  \resizebox{\columnwidth}{!}{
    \begin{tabular}{l|l|l|ll|l}
     \toprule
     \multirow{2}{*}{Task} & Development& Run & \multicolumn{2}{c|}{Accuracy} & \multirow{2}{*}{Ease of Composition}\\
     & time & time(s) & Recall & \multicolumn{1}{c|}{Precision} & \\
    \midrule
    ANGE~\cite{ZaMaFlairs2012HadithBio}
    & 2 months & 1.79 & 0.99 & 0.99 & 3000+ lines of code\\
    \framework & 3 hours & 7.24 & 0.99 & 0.93  & 8 MBFs and 4 MREs\\
    \midrule
    ATEEMA~\cite{ZaMa2012IJCLATime}
    & 1.5 months & 2.53 & 0.88  & 0.89  & 1000+ lines of code  \\
    \framework & 3 hours & 3.14 & 0.91  & 0.81  & 3 MBFs and 2 MREs\\
    \midrule
    Genealogy tree~\cite{ZaMaHaCicling2012Entity} 
    & 3 weeks & 0.74 & 0.96 & 0.98 & 3000+ lines of code\\
    \framework & 4 hours & 2.28 & 0.84 & 0.93  & 3 MBFs and 3 MREs\\
    \midrule
    NUMNORM & 1 week & 0.32 & 0.91 & 0.93  & 500 lines of code\\
    \framework & 1 hour & 1.53 & 0.91 & 0.90 & 3 MBFs/1 MRE/57 lines\\
    \bottomrule
    \end{tabular}%
    }
  \label{tab:results}%
\end{table}%

\begin{table}[tb!]
  \centering
  \caption{\framework MBF and user-defined relation accuracy }
  \resizebox{\columnwidth}{!}{
    \begin{tabular}{l|c|c|c|c}
     \toprule
     \multirow{2}{*}{Task} & \multicolumn{2}{c|}{MBF accuracy} & \multicolumn{2}{c}{relation accuracy}\\
     & Recall & Precision & Recall & Precision \\
    \midrule
    Narrator chain & 0.99 & 0.85 & 0.99 & 0.98 \\
    Number normalization & 0.99 & 0.99 & 0.97 & 0.95 \\
    Temporal entity & 0.99 & 0.52 & 0.98 & 0.89 \\
    Genealogy tree & 0.99 & 0.75 & 0.81 & 0.96 \\
    \bottomrule
    \end{tabular}%
    }
  \label{tab:mbfer}%
\end{table}%

%Recall refers to the fraction of the entities correctly detected against 
%the total number of entities available. 
%Precision refers to the fraction of correctly detected entities against the 
%total number of extracted entities. 
%Intuitively, precision denotes whether the system generated false positives.

For the temporal and number normalization cases, 
we evaluated the techniques against arbitrary text from issues of 
the Lebanese Assafir and Al-Akhbar newspapers
\footnote{available at \url{http://www.assafir.com} and 
\url{http://www.al-akhbar.com}.}. 
For the narrator chain case, we used
Musnad Ahmad, a hadith book, for evaluation. 
For the genealogical tree extraction we used 
an extract from the Genesis biblical text.

%\subsection{Comparison}

Table~\ref{tab:results} shows that \framework has a clear advantage over 
task specific techniques in the effort required to develop the application at 
a reasonable cost in terms of accuracy and run time. 
Developers with \framework needed three hours, three hours, four hours, and one hour 
to develop the narrator chain, temporal entity, genealogy, and number 
normalization case studies using \framework, respectively. 
However, the developers of ANGE, ATEEMA, GENTREE, and 
NUMNORM needed two months, one and a half months, 
three weeks, and one week, respectively. 
\framework needed eight MBFs and four MREs for narrator chain, 
three MBFs and 2 MREs for temporal entity, three MBFs and three MREs for 
genealogy, and three MBFs, one MRE, and 57 lines of code actions for the number normalization tasks. 
However, ANGE, ATEEMA, GENTREE, and NUMNORM required 
3,000+, 1,000+, 3,000+, and 500 lines of code, respectively.

\framework required reasonably more runtime than the task specific 
implementations and reported also reasonably acceptable and 
slightly less preision metrics with around
the same recall values. 
%a runtime of 7.29, 1.53, 3.14, and 2.28 seconds for 
%the narrator chain, temporal, genealogy, and number normalization tasks, respectively. 
%However, ANGE, ATEEMA, GENTREE, and NUMNORM required 1.79, 2.53, 0.74, and 0.32 seconds, respectively. 
%\framework required a runtime of 7.29, 1.53, 3.14, and 2.28 seconds for 
%the narrator chain, temporal, genealogy, and number normalization tasks, respectively. 
%However, ANGE, ATEEMA, GENTREE, and NUMNORM required 1.79, 2.53, 0.74, and 0.32 seconds, respectively. 
%In narrator chain, \framework scored 0.99\% recall and 0.93\% precision while ANGE scored 0.99\% recall and 0.99\% precision. 
%In temporal entity, \framework scored 0.91\% recall and 0.81\% precision while ATEEMA scored 0.88\% recall and 0.89\% precision. 
%In genealogy, \framework scored 0.84\% recall and 0.93\% precision while GENTREE scored 0.96\% recall and 0.98\% precision. 
%In number normalization, \framework scored 0.91\% recall and 0.90\% precision while NUMNORM scored 0.91\% recall and 0.93\% precision.

\vspace{-1em}
\subsection{Narrator chain case study}

%In this application, our target is to detect the narrator chains. 
A narrator chain is a sequence of narrators referencing each other. 
A sample narrator chain is shown in Table~\ref{tab:nchain}. 
The chain includes proper nouns (names), paternal entities, and referencing entities. 
ANGE uses Arabic morphological analysis, finite state machines, and graph transformations 
to extract named entities and relations including the narrator chains~\cite{ZaMaFlairs2012HadithBio}.

First, the MBF \cci{PN} checks the abstract category {\tt Name of Person}. 
MBF \cci{FAM} denotes ``family connector'' and checks the stem gloss ``son''. 
MBF \cci{TOLD} denotes referencing between narrators and checks the disjunction of 
the stems \RL{.hd_t}(spoke to), \RL{`n}(about), \RL{sm`}(heard), \RL{'_hbr}(told), and \RL{'nb-'}(inform). 
MBF \cci{MEAN} checks the stem \RL{`ny}(mean). 
MBFs \cci{BLESS}, \cci{GOD}, \cci{UPONHIM}, and \cci{GREET} check the 
stems \RL{.sll_A}, \RL{Al-ll_ah}, \RL{`ly}, and \RL{sllm}, respectively. 

Table~\ref{tab:nchain} presents the defined MRE expressions. 
MRE {\em name} is satisfied by one or more \cci{PN} tags optionally followed 
with a \cci{MEAN} tag. 
MRE \cci{nar} denotes narrator which is a complex Arabic name
composed as a sequence of Arabic names (\cci{name}) 
connected with family indicators (\cci{FAM}). 
The \cci{NONE} tags in \cci{nar} allow for unexpected words 
that can occur between names. 
%a complex Arabic name that is constructed
%a \cci{name} tag followed by zero or more 
%sequences of \cci{FAM} tag followed by \cci{name} tag 
%with up to three \cci{NONE} tags. 
MRE \cci{pbuh} denotes a praise phrase often associated with 
the end of a hadith (peace be upon him), 
and is the satisfied by the sequence of
\cci{BLESS}, \cci{GOD}, \cci{UPONHIM}, and \cci{GREET} tags. 
MRE \cci{nchain} denotes narrator chain, 
and is a sequence of narrators (\cci{nar})
separated with \cci{TOLD} tags, and optionally followed
by a \cci{pbuh} tag. 
%nal sequence of up to eight \cci{PN}, \cci{FAM}, or 
%\cci{NONE} tags followed by a \cci{pbuh} tag. 

\setcode{utf8}
\setarab
\begin{table}[tb!]
  \centering
  \caption{Narrator chain example.}
\resizebox{\columnwidth}{!}{
    \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
    \toprule 
    \notrrl{القعقاع} & \notrrl{بن} & \notrrl{عمارة} & \notrrl{عن} & \notrrl{جرير} & \notrrl{حدثنا} & \notrrl{سعيد} & \notrrl{بن} & \notrrl{قتيبة} & \notrrl{حدثنا} \\
    \midrule 
    \noarrl{القعقاع} & \noarrl{بن} & \noarrl{عمارة} & \noarrl{عن} & \noarrl{جرير} & \noarrl{حدثنا} & \noarrl{سعيد} & \noarrl{بن} & \noarrl{قتيبة} & \noarrl{حدثنا} \\
    \midrule
    PN    & FAM   & PN    & TOLD  & PN    & TOLD  & PN    & FAM   & PN    & TOLD \\
    \midrule
    name & & name & & name & & name &  & name & \\
    \midrule
    \multicolumn{3}{|c|}{nar} &       & nar   &       & \multicolumn{3}{c|}{nar} &  \\
    \midrule
    \multicolumn{10}{|c|}{nchain}
    \\
    \bottomrule
    \end{tabular}%
}
\begin{Verbatim}[fontsize=\relsize{-1},commandchars=\\\{\},codes={\catcode`$=3 \catcode`_=8}]
name:   PN ((MEAN)? PN)*;
nar:    name ((NONE)^3 FAM (NONE)^3 name)*;
pbuh:   BLESS GOD UPONHIM GREET;
nchain: ($s_1=$TOLD $s_2=$nar)+ ((PN|FAM|NONE)^8 pbuh)?
\end{Verbatim}
  \label{tab:nchain}%
  \vspace{-3em}
\end{table}%
\setcode{standard}

The first row in Table~\ref{tab:nchain} is an example narrator chain,
the second is the transliteration, the third 
shows the MBF tags. Rows 4, 5, and 6 show the 
matches for \cci{name}, \cci{nar}, and \cci{nchain},
respectively.
%
\framework assigns the symbols $s_1$ and $s_2$ for the 
MRE sub-expressions \cci{TOLD} and \cci{nar}, respectively. 
We define the relation $\langle s_2,s_2',s_1\rangle$ 
to relate sequences of narrators with edges labelled by the tags of \cci{TOLD} where 
$s_2'$ denotes the next match of \cci{nar} in the one or more MRE subexpression.
%The narrators in the example shown in Table~\ref{tab:nchain} are \RL{qtybT bn s`yd}, \RL{jryr}, and \RL{`mArT bn Alq`qA`}. 
%\transfalse
%The edges relating the entities are labeled by the word set \{\RL{.hdd_tnA}, \RL{.hdd_tnA}, \RL{`n}\} which contains all the %matches of the MBF \cci{TOLD}.
%\transtrue

Table~\ref{tab:mbfer} shows that \framework detected almost all the MBF matches 
with 99\% recall and 85\% precision and 
extracted user-defined relations with 98\% recall and 99\% precision.

For brevity, we omit the details of \framework temporal entity extraction, 
genealogy tree, and number normalization case studies, describe them shortly
below and provide a full description in the online Appendix.

\vspace{-1em}
\subsection{Temporal entity extraction}

Temporal entities are text chunks that express temporal information. 
Some represent absolute time such as \RL{Al_hAms mn 'Ab 2010}. 
Others represent relative time such as \RL{b`d _hmsT 'ayAm}, and quantities 
such as \RL{14 ywmA}. 
{\em ATEEMA} presents a temporal entity detection technique for the Arabic language using 
morphological analysis and finite state transducers~\cite{ZaMa2012IJCLATime}. 

%Table~\ref{tab:tbtags} shows the temporal MBFs. 
%MBF \cci{TIME} is explicit temporal words. 
%MBF \cci{NUM}, denotes numerals, and is digits or words referring to numbers. 
%MBF \cci{TIMEPREP} denotes temporal prepositions.

%% Table generated by Excel2LaTeX from sheet 'Sheet1'
%\begin{table}[tb!]
%  \centering
%  \caption{Temporal MBFs}
%  \resizebox{0.8\columnwidth}{!}{
%    \begin{tabular}{|r|r|r|}
%    \toprule
%    MBF & & Examples \\
%    \midrule
%    \multicolumn{1}{|c|}{\multirow{5}[0]{*}{TIME}} & unit  & \RL{dqyqT} (minute) \\
%    \multicolumn{1}{|c|}{} & relative & \RL{.gd} (tomorrow) \\
%    \multicolumn{1}{|c|}{} & range & \RL{rby`} (spring) \\
%    \multicolumn{1}{|c|}{} & nominal & \RL{'.hd} (Sunday) \\
%    \multicolumn{1}{|c|}{} & events & \RL{hjry} \\
%    \midrule
%    \multicolumn{1}{|c|}{\multirow{3}[0]{*}{NUM}} & digit & \RL{3} (3) \\
%    \multicolumn{1}{|c|}{} & word  & \RL{_tmAnyn} (eighty) \\
%    \multicolumn{1}{|c|}{} & range & \RL{_tmAnynyAt} (eighties) \\
%    \midrule
%    \multicolumn{1}{|c|}{\multirow{4}[0]{*}{TIMEPREP}} & point & \RL{fy} (in) \\
%    \multicolumn{1}{|c|}{} & relative & \RL{qbl} (before) \\
%    \multicolumn{1}{|c|}{} & approximate & \RL{n.hw} (about) \\
%    \multicolumn{1}{|c|}{} & range & \RL{xlAl} (during) \\
%    \bottomrule
%    \end{tabular}%
%    }
%  \label{tab:tbtags}%
%\end{table}%
%
%MRE {\em mts}, denotes {\tt maybe time start}, and is a disjunction of \cci{NUM} tag or \cci{TIMEPREP} tag. 
%MRE \cci{dt}, denotes {\tt definitetime}, and is zero or more sequence of \cci{mts} tags and up to two 
%\cci{NONE} tags, \cci{TIME} tag, then an optional sub-expression. 
%The sub-expression is a sequence of zero or more sequence of up to two \cci{NONE} tags followed by \cci{mts} tag or \cci{TIME} tag followed by up to two \cci{NONE} tags and \cci{TIME} tag or \cci{NUM} tag. 
%The last sub-expression \cci{TIME|NUM} is introduced to ensure that the temporal match ends with a \cci{TIME} tag or \cci{NUM} tag and not \cci{TIMEPREP} tag.
%
%\begin{Verbatim}[fontsize=\relsize{-1},commandchars=\\\{\},codes={\catcode`$=3 \catcode`_=8}]
%mts : NUM | TIMEPREP;
%dt : ( $\stackrel{s_1}{mts}$ NONE^2)* $\stackrel{s_2}{TIME}$
%       ( (NONE^2 $\stackrel{s_3}{( mts|TIME )}$)* 
%         NONE^2 $\stackrel{s_4}{( TIME|NUM )}$ )?;
%\end{Verbatim}
%
%\framework assigns the symbols $s_1$, $s_2$, $s_3$, and $s_4$ for the sub-expressions \cci{mts}, \cci{TIME}, \cci{mts|TIME}, and \cci{TIME|NUM}, respectively. 
%The symbols are shown in the regular expression defined above. 
%Using these symbols, we define the user-defined relations $r_1=\langle s_1,s_2,\epsilon\rangle$, $r_2=\langle s_2,s_3,\epsilon\rangle$, and $r_3=\langle s_3,s_4,\epsilon\rangle$. 
%$r_1$ relates \cci{mts} matches to TIME matches. 
%$r_2$ relates \cci{mts|TIME} matches to TIME matches. 
%$r_3$ relates \cci{mts|TIME} matches to \cci{TIME|NUM} matches.
%
%% Table generated by Excel2LaTeX from sheet 'Sheet1'
%\begin{table}[tb!]
%  \centering
%  \caption{Temporal entity example}
%  \resizebox{\columnwidth}{!}{
%    \begin{tabular}{|r|r|r|r|r|r|r|r|}
%    \toprule
%    \RL{AlsnwAt} & \RL{'.s`b} & \RL{mn} & \RL{w_hms} & \RL{`jAf} & \RL{'^shr} & \RL{'rb`T} & \RL{b`d} \\
%    \midrule
%    TIME  & NONE  & NONE  & NUM   & NONE  & TIME  & NUM   & TIMEPREP \\
%    \midrule
%          &       &       & mts   &       &       & mts   & mts \\
%    \midrule
%    \multicolumn{8}{|c|}{definitetime} \\
%    \bottomrule
%    \end{tabular}%
%    }
%  \label{tab:tempex}%
%\end{table}%
%
%The first row in Table~\ref{tab:tempex} is a temporal entity Arabic text. 
%Each word is denoted with MBF tags based on its morphological features. 
%The matches of the MRE {\tt mts} and {\tt dt} are shown as tags in rows 3 and 4, respectively.

Table~\ref{tab:mbfer} shows that \framework detected almost all the MBF matches with 99\% recall, 
however it shows low precision (52\%). 
As for the semantic relation construction, \framework presents a 98\% recall and 89\% precision.

\vspace{-1em}
\subsection{Genealogy tree}

Biblical genealogical lists trace key biblical figures such as Israelite kings and
prophets with family relations. 
The family relations include wife and parenthood. 
A sample genealogical chunk of text is \RL{w wld hArAn lw.tA} 
meaning ``and Haran became the father of Lot''.

GENTREE~\cite{ZaMaHaCicling2012Entity} 
automatically extracts the genealogical family trees using morphology, 
finite state machines, and graph transformations. 
%
%We defined the MBFs \cci{MN}, \cci{FN}, and \cci{CONN}. 
%MBF \cci{MN}, denotes male name, and is defined by the {\tt male name} category. 
%MBF \cci{FN}, denotes female name, and is defined by the {\tt female name} category. 
%MBF \cci{CONN}, denotes connection, and is defined by the stem \RL{wld} (give birth to).
%
%We define the MREs \cci{fform} and \cci{sform}. 
%MRE \cci{fform}, denotes first form, and is \cci{MN} tag followed by an optional \cci{FN} tag 
%followed by a one or more sequences of \cci{CONN} and \cci{MN} tags.
%
%\begin{Verbatim}[fontsize=\relsize{-1},commandchars=\\\{\},codes={\catcode`$=3 \catcode`_=8}]
%fform : $\stackrel{s_1}{MN}$ NONE^4 $\stackrel{s_2}{FN}$? (NONE^10 $\stackrel{s_3}{CONN}$ NONE^4 $\stackrel{s_4}{MN}$)+
%\end{Verbatim}
%
%MRE \cci{sform}, denotes second form, and is \cci{CONN} tag followed by \cci{MN} or \cci{FN} tag then \cci{MN} tag. 
%
%\begin{Verbatim}[fontsize=\relsize{-1},commandchars=\\\{\},codes={\catcode`$=3 \catcode`_=8}]
%sform : $\stackrel{s_5}{CONN}$ NONE^4 $\stackrel{s_6}{(MN|FN)}$ NONE^4 $\stackrel{s_7}{MN}$
%\end{Verbatim}
%
%MRE \cci{geneinfo}, denotes genealogical information, and is \cci{fform} tag or \cci{sform} tag.
%
%\begin{Verbatim}[fontsize=\relsize{-1}]
%geneinfo : fform | sform
%\end{Verbatim}
%
%\framework assigns the symbols $s_1$, $s_2$, $s_3$, $s_4$, $s_5$, $s_6$, and $s_7$ for the MRE sub-expressions \cci{MN}, \cci{FN}, \cci{CONN}, \cci{MN}, \cci{CONN}, \cci{MN|FN}, and \cci{MN}, respectively. 
%These symbols are shown over the sub-expressions in the defined MREs.
%
%Based on those symbols, we define the user-defined relations $r_1=\langle s_1,s_4,s_3\rangle$, $r_2=\langle s_1,s_2,``spouse''\rangle$, $r_3=\langle s_2,s_4,s_3\rangle$, and $r_4=\langle s_6,s_7,s_5\rangle$. 
%$r_1$ relates $s_1$ matches to $s_4$ matches with an edge labeled with $s_3$ matches. 
%This relation indicates that entity $s_1$ is the father of $s_4$. 
%$r_2$ relates $s_2$ matches to $s_1$ matches with an edge labeled by {\tt spouse}. 
%This relation indicates that the female is the male's spouse. 
%$r_3$ relates $s_4$ matches to $s_2$ matches using an edge labeled by $s_3$. 
%This relation indicates that the male is the female's child. 
%$r_4$ relates $s_6$ matches to $s_7$ matches using an edge labeled by $s_5$ matches. 
%This relation indicates that $s_7$ match is the child of $s_6$.
%
Table~\ref{tab:mbfer} shows that \framework detected 
MBF matches with 99\% recall, and 75\% precision, and
extracted user-defined relations with 81\% recall and 96\% precision.

\subsection{Number normalization}
\label{sec:sec:number}

We implemented a number normalization extractor using \framework and 
compared it with {\em NUMNORM}, a 
C++ implementation for number normalization.

%NUMNORM reads an Arabic text as input, extracts the text chunks with numerical information, and normalizes them. 
%NUMNORM uses the in-house morphological analyzer, {\em Sarf}, to identify the words referring to numbers. 
%Sarf provides a {\tt Number} category that tags all words with numerical information. 
%In the normalization algorithm, NUMNORM identifies three different categories for numbers;
%each with different behavior in normalization. 
%The categories are:
%\begin{itemize}
%\item DT, denoting digits and tens
%\item H, denoting hundred
%\item TMB, denoting thousand, million, and billion
%\end{itemize}
%
%NUMNORM retrieves the number referring to a word through a fixed map. 
%This map takes the word gloss as input and returns the matching number if found. 
%For example, the map returns 100 for the input gloss {\tt hundred}. 
%As for the normalization of more than one word, such as \RL{'lfyn w-'rb`T `^sr} (2014), 
%the normalization algorithm used for each category is shown in Figure~\ref{fig:numnormalgo}.  
%The algorithm uses Boolean variables and three integer variables. 
%The three integer variables are previous, current, and currentH for hundred. 
%The main steps in the algorithm are as follows. 
%Hundred is multiplied to previous digit if found, else saved. 
%Digits and tens are added to previous hundred if found, else added to current. 
%TMB match is multiplied by the previous hundred or DT if found, 
%else saved in current.

\newcommand*{\fvtextcolor}[2]{\textcolor{#1}{#2}}

\begin{figure}[tb!]
\centering
  \begin{tabular}{p{3.5cm}p{3.5cm}}
\begin{Verbatim}[fontsize=\relsize{-3.5},frame=single,label=TMB algorithm,commandchars=\\\[\]] 
cout << \fvtextcolor[red][$s1.text];
if(isHundred) {
  if(current != 0) {
    previous += current;
  }
  current = currentH*\fvtextcolor[red][$s1.number];
  currentH = 0;
  isHundred = false;
  isKey = true;
} else if(current == 0) {
  
  current=\fvtextcolor[red][$s1.number];
  isKey = true;
} else if(!isKey) {

  isKey = true;
  current = current*\fvtextcolor[red][$s1.number];
} else {
  previous += current;
  current = \fvtextcolor[red][$s1.number];
}
\end{Verbatim}
&
\begin{Verbatim}[fontsize=\relsize{-3.5},frame=single,label=DT algorithm,commandchars=\\\[\]] 
if(isHundred) {
  currentH +=\fvtextcolor[red][$s0.number];
} else if(current == 0) {
  current=\fvtextcolor[red][$s0.number];
} else if(isKey) {
  previous += current;
  current = \fvtextcolor[red][$s0.number];
} else {
  current += \fvtextcolor[red][$s0.number]; }
isKey = false;
\end{Verbatim}

\begin{Verbatim}[fontsize=\relsize{-3.5},frame=single,label=H algorithm,commandchars=\\\[\]] 
isHundred = true;
if(current == 0)  {
  currentH=\fvtextcolor[red][$s2.number];
} else if(!isKey) {
  currentH = current*\fvtextcolor[red][$s2.number];
  current = 0;
} else {
  currentH = \fvtextcolor[red][$s2.number];}
isKey = false;
\end{Verbatim}
\\ 
\end{tabular}
\caption{Actions for TMB, DT, and H MRE expressions.}
\label{fig:numnormalgo}
  \vspace{-1em}
\end{figure}

%Using \framework, we designed an MRE to detect the numerical entities. 
%We added actions to the MRE to normalize matches. 
First, we defined the MBF formulae \cci{DT}, \cci{H}, and \cci{TMB}
to denote (1) digits and tens, (2) hundreds, and (3) 
thousands, millions, and billions, respectively.

The \cci{num} MRE 
\cci{(DT|TMB|H)+} is one or more \cci{DT}, \cci{TMB}, or \cci{H} tags. 
\framework assigns the symbols $s_1$, $s_2$, and $s_3$ 
for the sub-expressions \cci{DT}, \cci{TMB}, and \cci{H}, respectively. 
Figure~\ref{fig:numnormalgo} shows the actions associated with the 
\cci{DT}, \cci{TMB}, and \cci{H} subexpressions that cumulatively compute 
the numeric value of the numeric expression match.
The actions use \framework API to access features of the matches such 
as the text (\cci{\$s1.text}) and the numeric 
value (\cci{\$s1.number}). 
of literal numbers such as digits and numbers from one to ten. 

\framework also assigns the symbol $s_3$ for the sub-expression \cci{DT|TMB|H}. 
Accordingly, we define the user-defined relation $\langle s3,s3',\epsilon\rangle$. 
This relation identifies the matches of $s_3$ as entities and relates them successively with non-labelled edges.

Table~\ref{tab:mbfer} shows high accuracy in MBF tagging with 99\% recall and 99\% precision, and
high accuracy in user-defined relation extraction with 97\% recall and 95\% precision.
