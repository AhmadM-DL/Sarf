\section*{Reviewer 4 comments}
\textit{Comments to the Author}\\

This work presents MERF; a GUI-enabled regular expressions 
based tool for entity and relational entity extraction, 
enhanced for Arabic text by enabling morphology-based matching.

\begin{enumerate}[leftmargin=0mm,label=\bfseries CommentR2.\arabic*]


\item \label{Review.4.1} 
Clarity:   
It is not clear how to associate code actions with 
subexpressions!

\answer{
  We elaborate the use of code actions in Subsection~\ref{subsec:numnorm} 
    by introducing Figure~\ref{fig:numnormalgo} and discussing it 
    in the corresponding case study. 
}

\done{
  Discussion of the code actions is pending...
}

\item \label{Review.4.1} 
Correctness :  
- $Syn^k$ introduces a lot of noise especially if $k$ is large. 

\answer{
  Your note is accurate, this is why we limit the degree (k) to 7.
  We further elaborate on this by introducing the following in the paper; Subsection~\ref{subsec:grammar}.
  \begin{quote}
  We limit $k$ to a maximum of $7$ since we practically noticed that 
  (1) values above $7$ introduce significant semantic noise and
  (2) the computation is expensive without a bound. 
  \end{quote}
}

\done{
  Done: Use the same answer for Reviewer 3, and say why you used 7. 
}

\item \label{Review.4.1} 
In the results section, there is no standard evaluation. 
The evaluation is based on comparisons with non-standard 
task-specific tools. 
Also, the reported precision and recall are very sensitive 
to the quality of the annotator!

\answer{
  Same answer to reviewer 3 results... 
}

\itodo{
Say something about clarifying the evaluation process. 
}

\end{enumerate}

